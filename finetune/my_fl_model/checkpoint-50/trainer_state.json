{
  "best_metric": 2.2692646980285645,
  "best_model_checkpoint": "./my_fl_model/checkpoint-50",
  "epoch": 0.24752475247524752,
  "eval_steps": 50,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0049504950495049506,
      "grad_norm": 9.011418342590332,
      "learning_rate": 4.998766400914329e-05,
      "loss": 2.3093,
      "step": 1
    },
    {
      "epoch": 0.009900990099009901,
      "grad_norm": 9.488789558410645,
      "learning_rate": 4.995066821070679e-05,
      "loss": 2.1755,
      "step": 2
    },
    {
      "epoch": 0.01485148514851485,
      "grad_norm": 10.053448677062988,
      "learning_rate": 4.9889049115077005e-05,
      "loss": 2.1498,
      "step": 3
    },
    {
      "epoch": 0.019801980198019802,
      "grad_norm": 8.610875129699707,
      "learning_rate": 4.980286753286195e-05,
      "loss": 2.4438,
      "step": 4
    },
    {
      "epoch": 0.024752475247524754,
      "grad_norm": 12.172137260437012,
      "learning_rate": 4.9692208514878444e-05,
      "loss": 2.1814,
      "step": 5
    },
    {
      "epoch": 0.0297029702970297,
      "grad_norm": 10.99435043334961,
      "learning_rate": 4.9557181268217227e-05,
      "loss": 2.1098,
      "step": 6
    },
    {
      "epoch": 0.034653465346534656,
      "grad_norm": 8.25548267364502,
      "learning_rate": 4.939791904846869e-05,
      "loss": 2.3425,
      "step": 7
    },
    {
      "epoch": 0.039603960396039604,
      "grad_norm": 10.697144508361816,
      "learning_rate": 4.9214579028215776e-05,
      "loss": 2.2692,
      "step": 8
    },
    {
      "epoch": 0.04455445544554455,
      "grad_norm": 9.627314567565918,
      "learning_rate": 4.900734214192358e-05,
      "loss": 2.0264,
      "step": 9
    },
    {
      "epoch": 0.04950495049504951,
      "grad_norm": 7.849071979522705,
      "learning_rate": 4.877641290737884e-05,
      "loss": 2.2074,
      "step": 10
    },
    {
      "epoch": 0.054455445544554455,
      "grad_norm": 8.058116912841797,
      "learning_rate": 4.852201922385564e-05,
      "loss": 2.38,
      "step": 11
    },
    {
      "epoch": 0.0594059405940594,
      "grad_norm": 8.866073608398438,
      "learning_rate": 4.8244412147206284e-05,
      "loss": 2.4019,
      "step": 12
    },
    {
      "epoch": 0.06435643564356436,
      "grad_norm": 5.74725341796875,
      "learning_rate": 4.794386564209953e-05,
      "loss": 2.0627,
      "step": 13
    },
    {
      "epoch": 0.06930693069306931,
      "grad_norm": 10.771986961364746,
      "learning_rate": 4.762067631165049e-05,
      "loss": 2.3939,
      "step": 14
    },
    {
      "epoch": 0.07425742574257425,
      "grad_norm": 8.755023956298828,
      "learning_rate": 4.72751631047092e-05,
      "loss": 2.2843,
      "step": 15
    },
    {
      "epoch": 0.07920792079207921,
      "grad_norm": 8.708998680114746,
      "learning_rate": 4.690766700109659e-05,
      "loss": 2.1777,
      "step": 16
    },
    {
      "epoch": 0.08415841584158416,
      "grad_norm": 6.217965602874756,
      "learning_rate": 4.65185506750986e-05,
      "loss": 2.2014,
      "step": 17
    },
    {
      "epoch": 0.0891089108910891,
      "grad_norm": 9.066959381103516,
      "learning_rate": 4.610819813755038e-05,
      "loss": 2.304,
      "step": 18
    },
    {
      "epoch": 0.09405940594059406,
      "grad_norm": 10.574125289916992,
      "learning_rate": 4.567701435686404e-05,
      "loss": 2.391,
      "step": 19
    },
    {
      "epoch": 0.09900990099009901,
      "grad_norm": 7.4135661125183105,
      "learning_rate": 4.522542485937369e-05,
      "loss": 2.3321,
      "step": 20
    },
    {
      "epoch": 0.10396039603960396,
      "grad_norm": 12.415131568908691,
      "learning_rate": 4.4753875309392266e-05,
      "loss": 2.2043,
      "step": 21
    },
    {
      "epoch": 0.10891089108910891,
      "grad_norm": 5.995645999908447,
      "learning_rate": 4.426283106939474e-05,
      "loss": 2.2789,
      "step": 22
    },
    {
      "epoch": 0.11386138613861387,
      "grad_norm": 7.965423583984375,
      "learning_rate": 4.375277674076149e-05,
      "loss": 2.2487,
      "step": 23
    },
    {
      "epoch": 0.1188118811881188,
      "grad_norm": 7.939000606536865,
      "learning_rate": 4.3224215685535294e-05,
      "loss": 2.3677,
      "step": 24
    },
    {
      "epoch": 0.12376237623762376,
      "grad_norm": 6.63078498840332,
      "learning_rate": 4.267766952966369e-05,
      "loss": 2.3388,
      "step": 25
    },
    {
      "epoch": 0.12871287128712872,
      "grad_norm": 6.965202331542969,
      "learning_rate": 4.211367764821722e-05,
      "loss": 2.0541,
      "step": 26
    },
    {
      "epoch": 0.13366336633663367,
      "grad_norm": 6.467202186584473,
      "learning_rate": 4.1532796633091296e-05,
      "loss": 2.2663,
      "step": 27
    },
    {
      "epoch": 0.13861386138613863,
      "grad_norm": 7.09379768371582,
      "learning_rate": 4.093559974371725e-05,
      "loss": 2.3581,
      "step": 28
    },
    {
      "epoch": 0.14356435643564355,
      "grad_norm": 6.602327346801758,
      "learning_rate": 4.0322676341324415e-05,
      "loss": 2.1887,
      "step": 29
    },
    {
      "epoch": 0.1485148514851485,
      "grad_norm": 6.888584613800049,
      "learning_rate": 3.969463130731183e-05,
      "loss": 2.1811,
      "step": 30
    },
    {
      "epoch": 0.15346534653465346,
      "grad_norm": 9.575983047485352,
      "learning_rate": 3.905208444630327e-05,
      "loss": 2.2027,
      "step": 31
    },
    {
      "epoch": 0.15841584158415842,
      "grad_norm": 8.806585311889648,
      "learning_rate": 3.8395669874474915e-05,
      "loss": 2.1078,
      "step": 32
    },
    {
      "epoch": 0.16336633663366337,
      "grad_norm": 7.7147135734558105,
      "learning_rate": 3.7726035393759285e-05,
      "loss": 2.2478,
      "step": 33
    },
    {
      "epoch": 0.16831683168316833,
      "grad_norm": 6.710037708282471,
      "learning_rate": 3.704384185254288e-05,
      "loss": 2.1564,
      "step": 34
    },
    {
      "epoch": 0.17326732673267325,
      "grad_norm": 6.84800386428833,
      "learning_rate": 3.634976249348867e-05,
      "loss": 2.0889,
      "step": 35
    },
    {
      "epoch": 0.1782178217821782,
      "grad_norm": 10.215738296508789,
      "learning_rate": 3.564448228912682e-05,
      "loss": 2.176,
      "step": 36
    },
    {
      "epoch": 0.18316831683168316,
      "grad_norm": 6.110415935516357,
      "learning_rate": 3.4928697265869515e-05,
      "loss": 2.1282,
      "step": 37
    },
    {
      "epoch": 0.18811881188118812,
      "grad_norm": 6.5940423011779785,
      "learning_rate": 3.4203113817116957e-05,
      "loss": 2.1078,
      "step": 38
    },
    {
      "epoch": 0.19306930693069307,
      "grad_norm": 6.811112403869629,
      "learning_rate": 3.346844800613229e-05,
      "loss": 2.4204,
      "step": 39
    },
    {
      "epoch": 0.19801980198019803,
      "grad_norm": 13.20567512512207,
      "learning_rate": 3.272542485937369e-05,
      "loss": 2.3541,
      "step": 40
    },
    {
      "epoch": 0.20297029702970298,
      "grad_norm": 6.49724006652832,
      "learning_rate": 3.1974777650980735e-05,
      "loss": 2.297,
      "step": 41
    },
    {
      "epoch": 0.2079207920792079,
      "grad_norm": 6.041210651397705,
      "learning_rate": 3.121724717912138e-05,
      "loss": 2.3232,
      "step": 42
    },
    {
      "epoch": 0.21287128712871287,
      "grad_norm": 6.723599910736084,
      "learning_rate": 3.045358103491357e-05,
      "loss": 2.3005,
      "step": 43
    },
    {
      "epoch": 0.21782178217821782,
      "grad_norm": 9.204814910888672,
      "learning_rate": 2.9684532864643122e-05,
      "loss": 2.441,
      "step": 44
    },
    {
      "epoch": 0.22277227722772278,
      "grad_norm": 6.608050346374512,
      "learning_rate": 2.8910861626005776e-05,
      "loss": 2.3675,
      "step": 45
    },
    {
      "epoch": 0.22772277227722773,
      "grad_norm": 9.081682205200195,
      "learning_rate": 2.8133330839107608e-05,
      "loss": 2.0124,
      "step": 46
    },
    {
      "epoch": 0.23267326732673269,
      "grad_norm": 7.908810615539551,
      "learning_rate": 2.7352707832962865e-05,
      "loss": 2.4064,
      "step": 47
    },
    {
      "epoch": 0.2376237623762376,
      "grad_norm": 16.916839599609375,
      "learning_rate": 2.656976298823284e-05,
      "loss": 2.2258,
      "step": 48
    },
    {
      "epoch": 0.24257425742574257,
      "grad_norm": 8.424141883850098,
      "learning_rate": 2.578526897695321e-05,
      "loss": 2.3286,
      "step": 49
    },
    {
      "epoch": 0.24752475247524752,
      "grad_norm": 5.953058242797852,
      "learning_rate": 2.5e-05,
      "loss": 2.1559,
      "step": 50
    },
    {
      "epoch": 0.24752475247524752,
      "eval_loss": 2.2692646980285645,
      "eval_runtime": 0.4969,
      "eval_samples_per_second": 342.118,
      "eval_steps_per_second": 22.137,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 58169925304320.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
